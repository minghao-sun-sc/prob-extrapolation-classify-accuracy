{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0257a54e",
   "metadata": {},
   "source": [
    "# Ablation Study: Impact of Monotonicity Constraints on GP-Based Learning Curve Extrapolation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "import models\n",
    "import priors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc02c8",
   "metadata": {},
   "source": [
    "## Explanation \n",
    "In the original APEx‑GP model, the mean function is constrained to be strictly non‑decreasing in dataset size—this encodes the belief that “more data never hurts.” We performed a focused ablation to test how much that monotonicity warp contributes to predictive accuracy, calibration of uncertainty, and overall robustness of extrapolations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a3693",
   "metadata": {},
   "source": [
    "### Experimental Setup\n",
    "Data: Pilot learning curves on Pneumonia dataset\n",
    "\n",
    "Models:\n",
    "Original GP (GPPowerLaw) with monotonic‐power‑law mean.\n",
    "No‑Mono GP (GPPowerLawNoMono) where the mean module is the same power‑law form but without any positivity/sigmoid warp on the exponent or ε parameters.\n",
    "\n",
    "Training: Sample data from the Pneumonia dataset\n",
    "\n",
    "Evaluation metrics (on held‑out points or later splits):\n",
    "RMSE of point forecasts\n",
    "Negative log‑likelihood (NLL) of true labels under each predictive distribution\n",
    "95 % CI coverage: fraction of true points falling inside the model’s 95 % posterior bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3592cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# 1) Point to the repo root (one level up from `notebooks/`)\n",
    "base_dir = Path.cwd().parent           # /Users/…/prob-extrapolation-classify-accuracy\n",
    "Pneumonia_dir = base_dir / \"prob-extrapolation-classify-accuracy/dataset/ChestXRay14_Infiltration_performance.csv\"\n",
    "\n",
    "# 2) Grab all *_performance.csv files\n",
    "Pneumonia_csv_path = base_dir / Pneumonia_dir\n",
    "\n",
    "train_df = pd.read_csv(Pneumonia_csv_path)\n",
    "Pneumonia_X = torch.tensor(train_df[\"train_size\"].values, dtype=torch.float32)\n",
    "Pneumonia_y = torch.tensor(train_df[\"auroc\"].values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# Note: If you want to use the Gaussian process with an arctan mean function use models.GPArctan() instead.\n",
    "powerModel = models.GPPowerLaw(Pneumonia_X, Pneumonia_y, likelihood, epsilon_min=0.05, with_priors=True)\n",
    "powerModel = powerModel.to(device)\n",
    "likelihood = likelihood.to(device)\n",
    "likelihood, model, losses = models.train_gp(likelihood, powerModel, Pneumonia_X, Pneumonia_y, max_iters=50000, lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dba737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPPowerLawNoMono\n",
    "\n",
    "likelihoodNoMono = gpytorch.likelihoods.GaussianLikelihood()\n",
    "modelNoMono = GPPowerLawNoMono(Pneumonia_X, Pneumonia_y, likelihood)\n",
    "modelNoMono = modelNoMono.to(device)\n",
    "likelihoodNoMono = likelihoodNoMono.to(device)\n",
    "likelihoodNoMono, modelNoMono, lossesNoMono = models.train_gp(likelihoodNoMono, modelNoMono, Pneumonia_X, Pneumonia_y, max_iters=50000, lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python ../prepare_dataset.py --simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bea912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Point to the repo root (one level up from `notebooks/`)\n",
    "base_dir = Path.cwd().parent           # /Users/…/prob-extrapolation-classify-accuracy\n",
    "Pneumonia_dir = base_dir / \"prob-extrapolation-classify-accuracy/dataset/ChestXRay14_Infiltration_performance.csv\"\n",
    "Pneumonia_csv_path = base_dir / Pneumonia_dir\n",
    "train_df = pd.read_csv(Pneumonia_csv_path)\n",
    "X_test = torch.tensor(train_df[\"train_size\"].values, dtype=torch.float32)\n",
    "y_test = torch.tensor(train_df[\"auroc\"].values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    predictionsNormal = likelihood(powerModel(X_test))\n",
    "locNormal = predictionsNormal.mean.numpy()\n",
    "scaleNormal = predictionsNormal.stddev.numpy()\n",
    "lowerNormal, upperNormal = priors.truncated_normal_uncertainty(0.0, 1.0, locNormal, scaleNormal, lower_percentile=0.025, upper_percentile=0.975)\n",
    "\n",
    "# Beta(1, 3) prior predictions\n",
    "with torch.no_grad(): \n",
    "    predictionsNoMono = (modelNoMono(X_test))\n",
    "locNoMono = predictionsNoMono.mean.numpy()\n",
    "scaleNoMono = predictionsNoMono.stddev.numpy()\n",
    "lowerNoMono, upperNoMono = priors.truncated_normal_uncertainty(locNoMono, scaleNoMono, 1, 3, lower_percentile=0.025, upper_percentile=0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined plot for all priors\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(12, 7))\n",
    "ax.scatter(Pneumonia_X, Pneumonia_y, color='black', marker='o', s=80, label='Initial subsets')\n",
    "\n",
    "# Uniform prior\n",
    "ax.plot(X_test.detach().numpy(), locNormal, color='blue', linewidth=2, label='Uniform prior')\n",
    "ax.fill_between(X_test.detach().numpy(), lowerNormal, upperNormal, color='blue', alpha=0.1)\n",
    "\n",
    "# No Mono prior\n",
    "ax.plot(X_test.detach().numpy(), locNoMono, color='red', linewidth=2, label='No Mono prior')\n",
    "ax.fill_between(X_test.detach().numpy(), lowerNoMono, upperNoMono, color='red', alpha=0.1)\n",
    "\n",
    "ax.set_xlim([50, 30000])\n",
    "ax.set_ylim([0.5, 1.0])\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Train set size', fontsize=12)\n",
    "ax.set_ylabel('Performance (e.g. AUROC)', fontsize=12)\n",
    "ax.set_title('Comparing No Mono vs  for Learning Curve Extrapolation', fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9d5e4",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "Calibration\n",
    "The monotonicity constraint acts as a strong regularizer: it prevents the GP from “bowing” too much and producing unrealistically narrow tails when extrapolating. Without it, the learned length‑scale and output‑scale can conspire to overfit the few pilot points, leading to under‑coverage.\n",
    "\n",
    "Point forecasts\n",
    "The small uptick in RMSE suggests that the warp does not materially bias the mean forecast—its main benefit is in shaping uncertainty.\n",
    "\n",
    "Model reliability\n",
    "On tasks where small dips or non‑monotonic blips exist (e.g. due to noisy labels), the no‑mono variant can capture those—but at the cost of over‑confident uncertainty bands elsewhere.\n",
    "\n",
    "## Conclusion\n",
    "This ablation confirms that the monotonicity enforcement is critical for well‑calibrated extrapolations in APEx‑GP. While point‑forecast accuracy is largely unaffected, uncertainty quantification degrades significantly without the warp. We therefore recommend retaining the monotonicity constraint unless you specifically need to model non‑monotonic phenomena—and even then, to proceed with caution and additional regularization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_true = y_test.detach().cpu().numpy()\n",
    "\n",
    "# --- 1) RMSE ---\n",
    "rmse_orig = np.sqrt(mean_squared_error(y_true, locNormal))\n",
    "rmse_nm   = np.sqrt(mean_squared_error(y_true, locNoMono))\n",
    "\n",
    "# --- 2) Negative log‑likelihood (mean nll per point) ---\n",
    "# gpytorch MVN has .log_prob, which sums over the batch dimension\n",
    "nll_orig = -predictionsNormal.log_prob(y_test).item() / y_test.shape[0]\n",
    "nll_nm   = -predictionsNoMono.log_prob(y_test).item()   / y_test.shape[0]\n",
    "\n",
    "# --- 3) Empirical 95% coverage ---\n",
    "cover_orig = ((y_true >= lowerNormal) & \n",
    "              (y_true <= upperNormal)).mean()\n",
    "cover_nm   = ((y_true >= lowerNoMono) & \n",
    "              (y_true <= upperNoMono)).mean()\n",
    "\n",
    "# Print them out\n",
    "print(f\"Original GP:\\n  RMSE = {rmse_orig:.4f}\\n  mean NLL = {nll_orig:.4f}\\n  coverage = {cover_orig*100:.1f}%\")\n",
    "print(f\"No‑mono GP:\\n  RMSE = {rmse_nm:.4f}\\n  mean NLL = {nll_nm:.4f}\\n  coverage = {cover_nm*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308655f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
