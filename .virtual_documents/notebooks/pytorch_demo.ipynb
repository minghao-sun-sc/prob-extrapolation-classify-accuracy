


import torch

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)
# Note: GPUs need to be specifically requested through sbatch. Below is an
# example requesting an interactive session.
# srun -p preempt -t 7:00:00 -n 1 --mem=64g --gres=gpu:a100:1 --pty bash





from torchvision.io import read_image
import matplotlib.pyplot as plt

path = '/cluster/tufts/hugheslab/eharve06/Chest_X-Ray/train/NORMAL/IM-0115-0001.jpeg'
image = read_image(path).float()
plt.imshow(image.permute(1, 2, 0).detach().numpy()/255, cmap='gray')
plt.axis('off')
plt.show()





import torchvision

# Load pretrained weights
weights = torchvision.models.ViT_B_16_Weights.DEFAULT
# Load ViT with pretrained weights
model = torchvision.models.vit_b_16(weights=torchvision.models.ViT_B_16_Weights(weights))





import torch.nn as nn

class Identity(nn.Module):
    def __init__(self):
        super(Identity, self).__init__()
        
    def forward(self, x):
        return x
    
# Remove classification head
model.heads = Identity()
model.eval()
model.to(device)
# Note: If you are using GPUs make sure to load your model to the GPUs.





# ViT expects normalized input of shape (batch_size, 3, 224, 224)
c, w, h = image.shape
print('Shape of original image: {}'.format(image.shape))
center_crop = torchvision.transforms.CenterCrop(min(w, h))
image = center_crop(image)
image = torchvision.transforms.functional.resize(image, size=(224, 224))
image = image.expand(3, 224, 224)
mean = torch.tensor([[[0.485]], [[0.456]], [[0.406]]])
std = torch.tensor([[[0.229]], [[0.224]], [[0.225]]])
image = ((image/255)-mean)/std
# Note: We normalized our input image with the mean and std of the pretrained 
# model see https://pytorch.org/vision/main/models/vision_transformer.html.
# Given enough training data, we should use the mean and std of our training
# data and not the mean and std of the pretrained model.
print('Shape of input image: {}'.format(image[None,:,:,:].shape))
encoded_image = model(image[None,:,:,:])
print('Shape of encoded image: {}'.format(encoded_image.shape))



